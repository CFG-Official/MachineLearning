{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform  \n",
    "\n",
    "def get_device():\n",
    "    \"\"\"\n",
    "    Function to determine the device type based on the node name.\n",
    "    It uses a dictionary to map node names to device types.\n",
    "\n",
    "    :return: device type as a string\n",
    "    :raises Exception: if node name is not found in the device_map dictionary\n",
    "    \"\"\"\n",
    "    device_map = {\n",
    "        \"PC-Cristian\": \"cuda\",\n",
    "        \"Dell-G5-15-Alexios\": \"cuda\",\n",
    "        \"MacBook-Pro-di-Cristian.local\": \"mps\",\n",
    "        \"MacBookProDiGrazia\": \"cpu\",\n",
    "        \"DESKTOP-RQVK8SI\":\"cuda\",\n",
    "        \"MacBook-Pro.station\":\"mps\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        return device_map[platform.uname().node]\n",
    "    except KeyError:\n",
    "        raise Exception(\"Node name not found. Please add your node name and its corresponding device to the dictionary.\")\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from project_paths import *\n",
    "\n",
    "def delete_ds_store_files(folder):\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file == \".DS_Store\":\n",
    "                file_path = os.path.join(root, file)\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted {file_path}\")\n",
    "\n",
    "# Specifica la cartella principale in cui cercare i file .DS_Store\n",
    "folder_path = data_folder_path\n",
    "\n",
    "delete_ds_store_files(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create YOLO dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, random\n",
    "\n",
    "def create_yolo_datset(splitted_frames_path, splitted_gt_path, yolo_dataset_path, num_frames_per_video=10):\n",
    "\n",
    "    # folders\n",
    "    # if yolo dataset folder, doesn't exist, create it\n",
    "    if not os.path.exists(yolo_dataset_path):\n",
    "        os.makedirs(yolo_dataset_path)  \n",
    "\n",
    "    # create the yolo dataset structure, we create a folder for train and a folder for val\n",
    "    if not os.path.exists(os.path.join(yolo_dataset_path, 'train')):\n",
    "        os.makedirs(os.path.join(yolo_dataset_path, 'train'))\n",
    "    if not os.path.exists(os.path.join(yolo_dataset_path, 'val')):\n",
    "        os.makedirs(os.path.join(yolo_dataset_path, 'val'))\n",
    "\n",
    "    # create the two inner folders: one for fire and one for no fire\n",
    "    if not os.path.exists(os.path.join(yolo_dataset_path, 'train', 'fire')):\n",
    "        os.makedirs(os.path.join(yolo_dataset_path, 'train', 'fire'))\n",
    "    if not os.path.exists(os.path.join(yolo_dataset_path, 'train', 'no_fire')):\n",
    "        os.makedirs(os.path.join(yolo_dataset_path, 'train', 'no_fire'))\n",
    "    if not os.path.exists(os.path.join(yolo_dataset_path, 'val', 'fire')):\n",
    "        os.makedirs(os.path.join(yolo_dataset_path, 'val', 'fire'))\n",
    "    if not os.path.exists(os.path.join(yolo_dataset_path, 'val', 'no_fire')):\n",
    "        os.makedirs(os.path.join(yolo_dataset_path, 'val', 'no_fire'))\n",
    "\n",
    "    # now we copy the images in the right folder\n",
    "    # we have to copy the images in the train folder and in the val folder\n",
    "    # for each folder in SPLITTED_FRAMES_DATASET/TRAINING_SET/0 we randomly sample num_frames_per_video frames and put them in dataset/train/no_fire\n",
    "    # for each folder in SPLITTED_FRAMES_DATASET/VALIDATION_SET/0 we randomly sample num_frames_per_video frames and put them in dataset/val/no_fire\n",
    "\n",
    "    count = 0\n",
    "    for folder in os.listdir(os.path.join(splitted_frames_path, 'TRAINING_SET','0')):\n",
    "        tot_frames = len(os.listdir(os.path.join(splitted_frames_path, 'TRAINING_SET','0')))\n",
    "        if tot_frames < num_frames_per_video:\n",
    "            num_frames_per_video = tot_frames\n",
    "        chosen_frames = []\n",
    "        for _ in range (num_frames_per_video):\n",
    "            # randomly sample a frame\n",
    "            frame = random.choice(os.listdir(os.path.join(splitted_frames_path, 'TRAINING_SET','0', folder)))\n",
    "            while frame in chosen_frames:\n",
    "                frame = random.choice(os.listdir(os.path.join(splitted_frames_path, 'TRAINING_SET','0', folder)))\n",
    "            chosen_frames.append(frame)\n",
    "            # copy the frame in the right folder\n",
    "            shutil.copy(os.path.join(splitted_frames_path, 'TRAINING_SET','0', folder, frame), os.path.join(yolo_dataset_path, 'train', 'no_fire', frame))\n",
    "            # rename the frame\n",
    "            os.rename(os.path.join(yolo_dataset_path, 'train', 'no_fire', frame), os.path.join(yolo_dataset_path, 'train', 'no_fire', str(count)+'.jpg'))\n",
    "            count += 1\n",
    "        \n",
    "    count = 0\n",
    "    for folder in os.listdir(os.path.join(splitted_frames_path, 'VALIDATION_SET','0')):\n",
    "        tot_frames = len(os.listdir(os.path.join(splitted_frames_path, 'VALIDATION_SET','0')))\n",
    "        if tot_frames < num_frames_per_video:\n",
    "            num_frames_per_video = tot_frames\n",
    "        chosen_frames = []\n",
    "        for _ in range (num_frames_per_video):\n",
    "            # randomly sample a frame\n",
    "            frame = random.choice(os.listdir(os.path.join(splitted_frames_path, 'VALIDATION_SET','0', folder)))\n",
    "            while frame in chosen_frames:\n",
    "                frame = random.choice(os.listdir(os.path.join(splitted_frames_path, 'VALIDATION_SET','0', folder)))\n",
    "            chosen_frames.append(frame)\n",
    "            # copy the frame in the right folder\n",
    "            shutil.copy(os.path.join(splitted_frames_path, 'VALIDATION_SET','0', folder, frame), os.path.join(yolo_dataset_path, 'val', 'no_fire', frame))\n",
    "            # rename the frame\n",
    "            os.rename(os.path.join(yolo_dataset_path, 'val', 'no_fire', frame), os.path.join(yolo_dataset_path, 'val', 'no_fire', str(count)+'.jpg'))\n",
    "            count += 1\n",
    "\n",
    "    # # for each folder in SPLITTED_FRAMES_DATASET/TRAINING_SET/1 we randomly sample num_frames_per_video frames starting from the frame indicated in the annotation file\n",
    "    # # and put them in dataset/train/fire\n",
    "    # # for each folder in SPLITTED_FRAMES_DATASET/VALIDATION_SET/1 we randomly sample num_frames_per_video frames starting from the frame indicated in the annotation file\n",
    "    # # and put them in dataset/val/fire\n",
    "\n",
    "    count = 0    \n",
    "    num_frames = 0\n",
    "    num_folders = 0\n",
    "    for folder in os.listdir(os.path.join(splitted_frames_path, 'TRAINING_SET','1')):\n",
    "        num_folders += 1\n",
    "        tot_frames = len(os.listdir(os.path.join(splitted_frames_path, 'TRAINING_SET','1')))\n",
    "        if tot_frames < num_frames_per_video:\n",
    "            num_frames_per_video = tot_frames\n",
    "        chosen_frames = []\n",
    "        # get the annotation file corresponding to the folder\n",
    "        annotation_file = folder.replace(\"mp4\", \"rtf\")\n",
    "        # open the annotation file\n",
    "        with open(os.path.join(splitted_gt_path, 'TRAINING_SET', '1', annotation_file), 'r') as f:\n",
    "            # get the frame in which the fire starts\n",
    "            start_frame = int(f.readline().split(',')[0])\n",
    "            # randomly sample a frame whose number starts from start_frame\n",
    "            available_frames = []\n",
    "            for _ in range (num_frames_per_video):\n",
    "                for frame in os.listdir(os.path.join(splitted_frames_path, 'TRAINING_SET','1', folder)):\n",
    "                    if int(frame.split('.')[0])>=start_frame:\n",
    "                        available_frames.append(frame)\n",
    "                frame = random.choice(available_frames)\n",
    "                while frame in chosen_frames:\n",
    "                    frame = random.choice(available_frames)\n",
    "                chosen_frames.append(frame)\n",
    "                num_frames += 1\n",
    "                # copy the frame in the right folder\n",
    "                shutil.copy(os.path.join(splitted_frames_path, 'TRAINING_SET','1', folder, frame), os.path.join(yolo_dataset_path, 'train', 'fire', frame))\n",
    "                # rename the frame\n",
    "                os.rename(os.path.join(yolo_dataset_path, 'train', 'fire', frame), os.path.join(yolo_dataset_path, 'train', 'fire', str(count)+'.jpg'))\n",
    "                count += 1\n",
    "\n",
    "    count = 0\n",
    "    for folder in os.listdir(os.path.join(splitted_frames_path, 'VALIDATION_SET','1')):\n",
    "        tot_frames = len(os.listdir(os.path.join(splitted_frames_path, 'VALIDATION_SET','1')))\n",
    "        if tot_frames < num_frames_per_video:\n",
    "            num_frames_per_video = tot_frames\n",
    "        chosen_frames = []\n",
    "        # get the annotation file corresponding to the folder\n",
    "        annotation_file = folder.replace(\"mp4\", \"rtf\")\n",
    "        # open the annotation file\n",
    "        with open(os.path.join(splitted_gt_path, 'VALIDATION_SET', '1', annotation_file), 'r') as f:\n",
    "            # get the frame in which the fire starts\n",
    "            start_frame = int(f.readline().split(',')[0])\n",
    "            # randomly sample a frame whose number starts from start_frame\n",
    "            available_frames = []\n",
    "            for _ in range (num_frames_per_video):\n",
    "                for frame in os.listdir(os.path.join(splitted_frames_path, 'VALIDATION_SET','1', folder)):\n",
    "                    if int(frame.split('.')[0])>=start_frame:\n",
    "                        available_frames.append(frame)\n",
    "                frame = random.choice(available_frames)\n",
    "                while frame in chosen_frames:\n",
    "                    frame = random.choice(available_frames)\n",
    "                chosen_frames.append(frame)\n",
    "                # copy the frame in the right folder\n",
    "                shutil.copy(os.path.join(splitted_frames_path, 'VALIDATION_SET','1', folder, frame), os.path.join(yolo_dataset_path, 'val', 'fire', frame))\n",
    "                # rename the frame\n",
    "                os.rename(os.path.join(yolo_dataset_path, 'val', 'fire', frame), os.path.join(yolo_dataset_path, 'val', 'fire', str(count)+'.jpg'))\n",
    "                count += 1\n",
    "\n",
    "create_yolo_datset(splitted_frames_path, splitted_annotations_path, yolo_folder_path, num_frames_per_video=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open all the images in yolo_dataset and resize them to 224x224\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def resize_images(dataset_path, img_size=224):\n",
    "\n",
    "    folders = ['train', 'val']\n",
    "    subfolders = ['fire', 'no_fire']\n",
    "\n",
    "    for folder in folders:\n",
    "        for subfolder in subfolders:\n",
    "            for image in tqdm(os.listdir(os.path.join(dataset_path, folder, subfolder))):\n",
    "                img = Image.open(os.path.join(dataset_path, folder, subfolder, image))\n",
    "                img = img.resize((img_size, img_size))\n",
    "                img.save(os.path.join(dataset_path, folder, subfolder, image))\n",
    "\n",
    "resize_images(yolo_folder_path, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n-cls.pt\")  # load a pretained model\n",
    "\n",
    "model.train(data=yolo_folder_path, imgsz=IMAGE_SIZE, epochs=50, batch_size = 128, device=device, save_period=1)  # train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate a trained model\n",
    "yolo_weights_path = \"../weights/best_custom.pt\"\n",
    "test_videos_folder = \"../test_data/TEST_SET\"\n",
    "test_frames_folder = \"../yolo_dataset/test\"\n",
    "\n",
    "# create the test frames folder if it doesn't exist\n",
    "if not os.path.exists(test_frames_folder):\n",
    "    os.mkdir(test_frames_folder)\n",
    "\n",
    "model = YOLO(yolo_weights_path)  # load a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os, glob, tqdm, torch\n",
    "import pandas as pd\n",
    "\n",
    "# create dataframe to which save if a clip is fire or not and the discovering frame\n",
    "df = pd.DataFrame(columns=['video', 'fire', 'frame'])\n",
    "\n",
    "for video in tqdm.tqdm(glob.glob(os.path.join(test_videos_folder, \"**\"), recursive=True)):\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        memory = []\n",
    "        \n",
    "    if os.path.isdir(video):\n",
    "        continue\n",
    "    # Process the video\n",
    "    ret = True\n",
    "    cap = cv2.VideoCapture(video) # Decodifica lo streaming\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) # Ottiene il frame rate\n",
    "    f = 0\n",
    "    fire = 0\n",
    "    while ret:\n",
    "        ret, img = cap.read() # Chiamando read leggiamo il frame successivo dallo stream\n",
    "        if ret: # ret è false quando non ci sono più frame da leggere\n",
    "            f += 1\n",
    "            # Il tensore img letto viene trasformato tramite la classe PIL e lo salviamo\n",
    "            frame_name = os.path.join(test_frames_folder, \"{:05d}.jpg\".format(f))\n",
    "            \n",
    "            cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "            cv2.imwrite(frame_name, img)\n",
    "            # evaluate YOLO model on the frame\n",
    "            results = model.predict(frame_name, verbose=False)\n",
    "            # if it is a fire tell the video is fire and continue with the next video\n",
    "            for result in results:\n",
    "                if result.probs.data.tolist()[0] >= 0.5:\n",
    "                    fire = 1\n",
    "                    ret = 0\n",
    "                    break\n",
    "    # save the result in the dataframe\n",
    "    df.loc[len(df)] = [video, fire, round(f/fps)]\n",
    "    #empty the test frames folder\n",
    "    # for frame in os.listdir(test_frames_folder):\n",
    "    #     os.remove(os.path.join(test_frames_folder, frame))\n",
    "\n",
    "    # Calcolo delle dimensioni della memoria occupata\n",
    "    if torch.cuda.is_available():\n",
    "        memory_bytes = torch.cuda.memory_allocated()\n",
    "        memory.append( memory_bytes / (1024 ** 2))\n",
    "    \n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = '../test_data/GT_TEST_SET'\n",
    "# modify the first column of the dataframe to remove the path and keep only the video name\n",
    "df['video'] = df['video'].apply(lambda x: x.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tn = 0\n",
    "delays = []\n",
    "\n",
    "video_counter = 0\n",
    "guard_time = 5 # seconds\n",
    "\n",
    "for i in range(len(df)):\n",
    "\n",
    "    annotation_file = df['video'][i].replace(\"mp4\", \"rtf\")\n",
    "\n",
    "    with open(os.path.join(annotations_path, annotation_file), 'r') as f:\n",
    "\n",
    "        line = f.readline()\n",
    "\n",
    "        if line and df['fire'][i] == 1:\n",
    "            # There is a fire in the video\n",
    "            g_frame = int(line.split(',')[0])\n",
    "            p_frame = df['frame'][i]\n",
    "            \n",
    "            if p_frame >= max(0, g_frame - guard_time):\n",
    "                # Detection is fast enough\n",
    "                delays.append(abs(p_frame - g_frame))\n",
    "                tp += 1\n",
    "            else:\n",
    "                # Detection is not fast enough\n",
    "                fp += 1\n",
    "        elif not line and df['fire'][i]==1:\n",
    "            fp += 1\n",
    "        elif line and df['fire'][i]==0:\n",
    "            fn += 1\n",
    "        elif not line and df['fire'][i]==0:\n",
    "            tn += 1\n",
    "        else:\n",
    "            print(\"Something went wrong\")\n",
    "\n",
    "# Compute precision, recall and f1 score\n",
    "# Count the number of true positives, false positives and false negatives\n",
    "\n",
    "try:\n",
    "    precision = tp/(tp+fp)\n",
    "except ZeroDivisionError:\n",
    "    precision = 0\n",
    "try:\n",
    "    recall = tp/(tp+fn)\n",
    "except ZeroDivisionError:\n",
    "    recall = 0\n",
    "\n",
    "try:\n",
    "    D = sum(delays)/len(delays) \n",
    "    Dn = max(0, 60-D)/60\n",
    "except:\n",
    "    print(\"Can't calculate D because no fire detected in the test set\")\n",
    "    D = float(\"inf\")\n",
    "    Dn = 0\n",
    "\n",
    "# Print results\n",
    "print(\"..:: RESULTS ::..\")\n",
    "\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F-score: {:.4f}\".format(2 * precision * recall / (1e-10 + precision + recall)))\n",
    "print(\"Detection mean error: {:.4f}\".format(D))\n",
    "print(\"Detection delay: {:.4f}\".format(Dn))\n",
    "    \n",
    "print(\"Final score numerator: {:.4f}\".format(precision * recall * Dn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
