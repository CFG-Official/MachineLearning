{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metti qua il tuo path al dataset\n",
    "path = \"../data/IMAGE_TRAINING_SET\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# define function that walks through each directory and subdirectory\n",
    "def walk_through_dir(dir_path):\n",
    "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
    "\n",
    "walk_through_dir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "#setup path for our data files\n",
    "fire_dir = Path(path+\"/1\")\n",
    "non_fire_dir = Path(path+\"/0\")\n",
    "\n",
    "fire_dir, non_fire_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import albumentations\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    transforms.GaussianBlur(kernel_size = 3, sigma = 0.1),\n",
    "])\n",
    "\n",
    "\n",
    "# preprocess = albumentations.Sequential([\n",
    "#     albumentations.Resize(height=256, width=256, always_apply=True),\n",
    "#     albumentations.CenterCrop(height=224, width=224, always_apply=True),\n",
    "#     albumentations.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                 std=[0.229, 0.224, 0.225],\n",
    "#                                 max_pixel_value=255.,\n",
    "#                                 always_apply=True),\n",
    "# ])\n",
    "\n",
    "# augmentation = albumentations.Compose([\n",
    "#     albumentations.HorizontalFlip(p=0.5), # Flip orizzontale\n",
    "#     albumentations.Rotate(p=0.8, limit=15), # Rotazione\n",
    "#     albumentations.Blur(p=0.3), # Sfoca l'immagine\n",
    "#     albumentations.Sharpen(p=0.4),  # Accentua i bordi\n",
    "#     albumentations.RandomBrightnessContrast(p=0.2), # Cambia luminosità e contrasto\n",
    "#     # albumentations.ChannelShuffle(p=0.2), # Scambia i canali RGB\n",
    "#     # albumentations.ColorJitter(p=0.2), # Cambia colore\n",
    "#     # albumentations.Downscale(p=0.2), # Riduce la risoluzione\n",
    "#     # albumentations.Emboss(p=0.2), # Rilievo\n",
    "#     albumentations.HueSaturationValue(p=0.2), # Cambia tonalità, saturazione e valore\n",
    "#     # albumentations.RandomFog(p=0.7), # Nebbia\n",
    "#     # albumentations.RandomRain(p=0.3), # Pioggia\n",
    "#     # albumentations.RandomShadow(p=0.5), # Ombra\n",
    "#     # albumentations.Solarize(p=0.2), # Solarizzazione\n",
    "#     albumentations.UnsharpMask(p=0.2), # Maschera di contrasto\n",
    "# ], p=.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "#define data root directory\n",
    "root_dir = path\n",
    "\n",
    "#you can also apply data transformation using the `transforms` parameter here\n",
    "fire_dataset = ImageFolder(root_dir, transform=transforms.Compose([preprocess, augmentation]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the classes are the names of the files in the root folder\n",
    "class_names = fire_dataset.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class names as a dict\n",
    "class_dict = fire_dataset.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "# split the dataset into training, validation and testing\n",
    "rand_bytes = os.urandom(8) # generate 8 random bytes (64 bits) beacuse manual_seed needs a 64-bit integer (8 bytes)\n",
    "rand_int = int.from_bytes(rand_bytes, byteorder='big')\n",
    "train_dataset, valid_dataset, test_dataset = random_split(fire_dataset, [0.75, 0.15, 0.10], generator=torch.Generator().manual_seed(rand_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset), len(valid_dataset), len(test_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torch.nn import Linear\n",
    "\n",
    "def build_resnet18(num_outputs=1):\n",
    "    \n",
    "    model = models.resnet18(pretrained=True)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    for param in model.layer3.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    for param in model.layer4.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    model.fc = Linear(model.fc.in_features, num_outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# function to get trainable parameters of the give model\n",
    "def get_trainable_params(model):\n",
    "    params_to_update = []\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "    return params_to_update\n",
    "\n",
    "def build_mobilenet():\n",
    "    mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "    for param in mobilenet.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    mobilenet.classifier[1] = Linear(mobilenet.classifier[1].in_features, 1)\n",
    "\n",
    "    for param in mobilenet.features[8:].parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in mobilenet.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    return mobilenet\n",
    "\n",
    "    \n",
    "\n",
    "model = build_mobilenet()\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tensorboard import notebook\n",
    "import os\n",
    "\n",
    "def start_tensorboard(log_dir):\n",
    "  writer = SummaryWriter(os.path.join(\"runs\", log_dir))\n",
    "\n",
    "  # run tensorboard in background\n",
    "  ! killall tensorboard\n",
    "  %load_ext tensorboard\n",
    "  %tensorboard --logdir ./runs\n",
    "\n",
    "  notebook.list() # View open TensorBoard instances\n",
    "\n",
    "  return writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "\n",
    "def one_epoch(model, lossFunction, output_activation, optimizer, train_loader, val_loader, writer, epoch_num):\n",
    "  model.to(device)\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  i_start = epoch_num * len(train_loader)\n",
    "  for i, (X, y) in tqdm(enumerate(train_loader), desc=\"epoch {} - train\".format(epoch_num)):\n",
    "    if i == 0:\n",
    "      writer.add_image('first_batch', make_grid(X))\n",
    "\n",
    "    X = X.to(device)\n",
    "    y = y.to(device).float()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    o = model(X)\n",
    "    o = output_activation(o).squeeze()\n",
    "    l = lossFunction(o, y)\n",
    "\n",
    "\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    acc = ((o.detach() > .5) == y.detach()).float().mean()\n",
    "    \n",
    "    # print(\"- batch loss and accuracy : {:.7f}\\t{:.4f}\".format(l.detach().item(), acc))\n",
    "    writer.add_scalar('train/loss', l.detach().item(), i_start+i)\n",
    "    writer.add_scalar('train/acc', acc, i_start+i)\n",
    "\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    val_loss = []\n",
    "    val_corr_pred = []\n",
    "    for X, y in tqdm(val_loader, desc=\"epoch {} - validation\".format(epoch_num)):\n",
    "      X = X.to(device)\n",
    "      y = y.to(device).float()\n",
    "\n",
    "      o = model(X)\n",
    "      o = output_activation(o).squeeze()\n",
    "      val_loss.append(lossFunction(o, y))\n",
    "      val_corr_pred.append((o > .5) == y)\n",
    "\n",
    "    val_loss = torch.stack(val_loss).mean().item()\n",
    "    val_accuracy = torch.concatenate(val_corr_pred).float().mean().item()\n",
    "\n",
    "    # print(\"Validation loss and accuracy : {:.7f}\\t{:.4f}\".format(val_loss, val_accuracy))\n",
    "    writer.add_scalar('val/loss', val_loss, i_start+i)\n",
    "    writer.add_scalar('val/acc', val_accuracy, i_start+i)\n",
    "  return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import BCELoss, CrossEntropyLoss, Sigmoid, Softmax\n",
    "\n",
    "# learning parameters\n",
    "lossFunction, output_activation = BCELoss(), Sigmoid()\n",
    "batch_size = 256\n",
    "lr = .001\n",
    "momentum = .9\n",
    "lambda_reg = 0\n",
    "\n",
    "epochs = 300\n",
    "early_stopping_patience = 5\n",
    "\n",
    "optimizer = torch.optim.Adam(get_trainable_params(model),\n",
    "                          lr=lr,\n",
    "                          weight_decay=lambda_reg)\n",
    "\n",
    "# create output directory and logger\n",
    "experiment_name = \"image_train_mobilenet\"\n",
    "import os\n",
    "#!rm -rf resnet18_images\n",
    "os.makedirs(experiment_name)\n",
    "writer = start_tensorboard(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader_params = {\"batch_size\": batch_size, \"num_workers\": 2, \"pin_memory\": True}\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, **dataloader_params)\n",
    "val_loader = DataLoader(valid_dataset, shuffle=False, **dataloader_params)\n",
    "\n",
    "# early stopping and best model saving\n",
    "early_stopping_counter = early_stopping_patience\n",
    "min_val_loss = 1e10\n",
    "\n",
    "# training and validation\n",
    "val_losses = torch.zeros(epochs)\n",
    "val_accuracies = torch.zeros(epochs)\n",
    "for e in range(epochs):\n",
    "  print(\"EPOCH {}\".format(e))\n",
    "  val_loss, val_accuracy = one_epoch(model, lossFunction, output_activation, optimizer, train_loader, val_loader, writer, e)\n",
    "\n",
    "  # store the validation metrics\n",
    "  val_losses[e] = val_loss\n",
    "  val_accuracies[e] = val_accuracy\n",
    "  torch.save(val_losses, os.path.join(experiment_name,'val_losses.pth'))\n",
    "  torch.save(val_accuracies, os.path.join(experiment_name,'val_accuracies.pth'))\n",
    "\n",
    "  # save the best model and check the early stopping criteria\n",
    "  if val_loss < min_val_loss: # save the best model\n",
    "    min_val_loss = val_loss\n",
    "    early_stopping_counter = early_stopping_patience # reset early stopping counter\n",
    "    torch.save(model.state_dict(), os.path.join(experiment_name,'best_model.pth'))\n",
    "    print(\"- saved best model: val_loss =\", val_loss, \"val_accuracy =\", val_accuracy)\n",
    "\n",
    "  if e>0: # early stopping counter update\n",
    "    if val_losses[e] > val_losses[e-1]:\n",
    "        early_stopping_counter -= 1 # update early stopping counter\n",
    "    else:\n",
    "        early_stopping_counter = early_stopping_patience # reset early stopping counter\n",
    "  if early_stopping_counter == 0: # early stopping\n",
    "      break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader_params = {\"batch_size\": batch_size, \"num_workers\": 2, \"pin_memory\": True}\n",
    "val_loader = DataLoader(test_dataset, shuffle=False, **dataloader_params)\n",
    "\n",
    "model = build_mobilenet().to(device)\n",
    "model.load_state_dict(torch.load(os.path.join(experiment_name,'best_model.pth')))\n",
    "\n",
    "Y, Y_hat = [], []\n",
    "with torch.no_grad():\n",
    "  model.eval()\n",
    "  for X, y in val_loader:\n",
    "    Y.append(y)\n",
    "    Y_hat.append((output_activation(model(X.to(device))) > .5).squeeze().to(device))\n",
    "\n",
    "Y = torch.concatenate(Y).to(\"cpu\")\n",
    "Y_hat = torch.concatenate(Y_hat).to(\"cpu\")\n",
    "print(\"Test accuracy:\", (Y==Y_hat).float().mean().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Compute precision and recall and F-score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "confusion_matrix(Y, Y_hat)\n",
    "\n",
    "precision = precision_score(Y, Y_hat)\n",
    "recall = recall_score(Y, Y_hat)\n",
    "\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F-score: {:.4f}\".format(2 * precision * recall / (precision + recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_video_sample(X, y):\n",
    "    plt.figure()\n",
    "    plt.imshow(make_grid(X).numpy().transpose((1, 2, 0)))\n",
    "    plt.title(y)\n",
    "    plt.show()\n",
    "\n",
    "# analyze the false positives\n",
    "\n",
    "for i in range(len(Y)):\n",
    "  if Y[i] == 0 and Y_hat[i] == 1:\n",
    "    visualize_video_sample(test_dataset[i][0], test_dataset[i][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('MachineLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a2c952ceb315243f34ba302acbe0fb5218585a422897d4fb07b81cc17398136"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
