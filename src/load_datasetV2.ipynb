{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration setup\n",
    "All global notebook variables will be placed here for readability and maintainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "import gdown\n",
    "import random\n",
    "from project_paths import *\n",
    "import cv2, argparse, glob, PIL, tqdm, sys\n",
    "\n",
    "# Definition of global variables for the notebook\n",
    "raw_dataset_links = {\n",
    "    \"mivia\": (\n",
    "        \"https://drive.google.com/file/d/1tEz2wVQjPp1MjVHZLa-Z3uyVBnwljgGF/view?usp=sharing\",\n",
    "        \"https://drive.google.com/file/d/123AcAQCldRNE6iKpXuCaVtsaR3uHIOeN/view?usp=sharing\"\n",
    "    ),\n",
    "    \"custom\": (\n",
    "        \"https://drive.google.com/file/d/1eTDG_SbHkCo0OeVwRKugQ2vDV2csDx6q/view?usp=sharing\",\n",
    "        \"https://drive.google.com/file/d/1UjWkvzzezXNOkncas4Q-kP9X9VU2D0OE/view?usp=sharing\"\n",
    "    ),\n",
    "\n",
    "    \"mivia_custom_04_07\": (   # Dataset custom senza video duplicati e con numerazione corretta.\n",
    "                        # Fino ad adesso ne è stato testato solo l'effettivo scaricamento.\n",
    "                        # Si testerà l'estrazione dei frames a breve.\n",
    "        \"https://drive.google.com/file/d/13VJ-MGfrS_cvOwLvmiDlqmawGV0ebZGC/view?usp=sharing\",\n",
    "        \"https://drive.google.com/file/d/13TmHShb5tNa9doujghCNoFlB5pAJsJWz/view?usp=sharing\"\n",
    "    ),\n",
    "    \"mivia_custom_09_07\": (\n",
    "        \"https://drive.google.com/file/d/13n9lbNyJchDk5olfHzU6Oy_WQR7ZbPFX/view?usp=drive_link\",\n",
    "        \"https://drive.google.com/file/d/13lJY76imebgbovVc1asDm6GvuNkaF8u8/view?usp=drive_link\"\n",
    "    ),\n",
    "    \"mivia_custom_10_07\": (\n",
    "        \"https://drive.google.com/file/d/14-z_UsyDaPyGCTdXrXS2YDkGIfDfGQNJ/view?usp=drive_link\",\n",
    "        \"https://drive.google.com/file/d/13xXyOqp2ET_ySTzd7mP-qk8hs5x3y96g/view?usp=drive_link\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "SELECTED_DATASET = \"mivia_custom_10_07\"\n",
    "RELOAD_DATASET = False # If True, the dataset is reloaded from the links above, otherwise it is loaded from the local folder\n",
    "\n",
    "\n",
    "\n",
    "video_link, labels_link = raw_dataset_links[SELECTED_DATASET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_google_file(shader_url, output_name):\n",
    "  id_url = \"https://drive.google.com/uc?id=\" + shader_url.split(\"/\")[5]\n",
    "  gdown.download(id_url, output_name)\n",
    "\n",
    "\n",
    "def reload_data_folder_videos():\n",
    "    videos_name_file = \"VIDEOS.zip\"\n",
    "    shutil.rmtree(videos_path, ignore_errors=True)  # delete the folder\n",
    "    os.makedirs(videos_path, exist_ok=True)  # create a new one with the same name\n",
    "    download_google_file(video_link, videos_name_file)\n",
    "    zip_videos_path = videos_path / videos_name_file\n",
    "    shutil.move(videos_name_file, zip_videos_path)\n",
    "    shutil.unpack_archive(zip_videos_path, videos_path)\n",
    "    os.remove(zip_videos_path)\n",
    "    if (data_folder_path / \"__MACOSX\").exists():\n",
    "        shutil.rmtree(data_folder_path / \"__MACOSX\")\n",
    "\n",
    "\n",
    "def reload_data_folder_annotations():\n",
    "    labels_name_file = \"GT.zip\"\n",
    "    shutil.rmtree(train_original_annotations_path, ignore_errors=True)  # delete the folder\n",
    "    download_google_file(labels_link, labels_name_file)\n",
    "    zip_labels_path = data_folder_path / labels_name_file\n",
    "    shutil.move(labels_name_file, zip_labels_path)\n",
    "    shutil.unpack_archive(zip_labels_path, data_folder_path)\n",
    "    os.remove(zip_labels_path)    \n",
    "    os.makedirs(train_original_annotations_path)\n",
    "    old_no_fire_labels_folder_path = data_folder_path /\"GT_TRAINING_SET_CL0\"\n",
    "    old_fire_labels_folder_path = data_folder_path / \"GT_TRAINING_SET_CL1\"\n",
    "    shutil.move(old_no_fire_labels_folder_path, train_original_annotations_path)\n",
    "    shutil.move(old_fire_labels_folder_path, train_original_annotations_path)\n",
    "    os.rename(train_original_annotations_path / \"GT_TRAINING_SET_CL0\", train_original_annotations_path / \"0\")\n",
    "    os.rename(train_original_annotations_path / \"GT_TRAINING_SET_CL1\", train_original_annotations_path / \"1\")\n",
    "    if (data_folder_path / \"__MACOSX\").exists():\n",
    "        shutil.rmtree(data_folder_path / \"__MACOSX\")\n",
    "\n",
    "def reload_data_folder():\n",
    "    \n",
    "    if data_folder_path.exists():\n",
    "        shutil.rmtree(data_folder_path)  # delete the folder\n",
    "    \n",
    "    reload_data_folder_videos()\n",
    "    reload_data_folder_annotations()\n",
    "    \n",
    "    \n",
    "\n",
    "def check_data_folder(reload = False, size_limit=10):\n",
    "    \"\"\"\n",
    "    Checks if a folder exists and if its size (including subfolders) is less than a given limit.\n",
    "    If both conditions are met, the folder is deleted and recreated.\n",
    "\n",
    "    :param folder_path: path of the folder to check\n",
    "    :param size_limit: size limit in MB\n",
    "    \"\"\"\n",
    "\n",
    "    if reload:\n",
    "        reload_data_folder()\n",
    "        return\n",
    "\n",
    "    if data_folder_path.exists():\n",
    "        total_size = sum(f.stat().st_size for f in data_folder_path.glob('**/*') if f.is_file()) / (1024 * 1024)\n",
    "        if total_size < size_limit:\n",
    "            reload_data_folder()\n",
    "    else:\n",
    "        reload_data_folder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform  \n",
    "\n",
    "def get_device():\n",
    "    \"\"\"\n",
    "    Function to determine the device type based on the node name.\n",
    "    It uses a dictionary to map node names to device types.\n",
    "\n",
    "    :return: device type as a string\n",
    "    :raises Exception: if node name is not found in the device_map dictionary\n",
    "    \"\"\"\n",
    "    device_map = {\n",
    "        \"PC-Cristian\": \"cuda\",\n",
    "        \"Dell-G5-15-Alexios\": \"cuda\",\n",
    "        \"MacBook-Pro-di-Cristian.local\": \"mps\",\n",
    "        \"MacBookProDiGrazia\": \"cpu\",\n",
    "        \"DESKTOP-RQVK8SI\":\"cuda\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        return device_map[platform.uname().node]\n",
    "    except KeyError:\n",
    "        raise Exception(\"Node name not found. Please add your node name and its corresponding device to the dictionary.\")\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_folder(RELOAD_DATASET)\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(\"ONFIRE2023_Example_Code\")\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "download_google_file(\"https://drive.google.com/file/d/1rXMCtpus2i2UDdSBD9RwWAxnT0wrrXOk/view?usp=sharing\", \"test_code.zip\")\n",
    "shutil.unpack_archive(\"test_code.zip\", \".\")\n",
    "os.remove(\"test_code.zip\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract frames from video files\n",
    "\n",
    "Riconduciamo il problema da un dominio di video ad un dominio di immagini andando a selezionare i frame di ogni video e disponendoli in una sottocartella. È importante salvare i frame con qualità alta, altrimenti distorciamo l'informazione data al classificatore."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use ffmpeg to faster the frame extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(original_frames_path, exist_ok=True)\n",
    "\n",
    "file_list = [path for path in Path(videos_path).rglob(\"*\") if path.is_file()]\n",
    "for video in tqdm.tqdm(file_list):\n",
    "  output_video_frames_folder = Path(os.path.join(original_frames_path, video.relative_to(videos_path)))\n",
    "  if output_video_frames_folder.is_dir():\n",
    "    continue\n",
    "  \n",
    "  os.makedirs(output_video_frames_folder, exist_ok=True)\n",
    "  os.system(\"ffmpeg -i {} {}/{}.jpg\".format(video, output_video_frames_folder, \"%05d\"))\n",
    "  shutil.rmtree(output_video_frames_folder / \"__MACOSX\", ignore_errors=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(source_path, destination_path, mode=\"classic\", p=[0.8,0.1,0.1]):\n",
    "    \"\"\"\n",
    "    If mode is \"classic\", it splits the dataset into train, validation and test sets.\n",
    "    If mode is \"k-fold\", it splits only the test. In this case other videos remain in the training set folder.\n",
    "    \"\"\"\n",
    "    no_fire_original_frames_folder = source_path /'0'\n",
    "    fire_original_frames_folder = source_path / '1'\n",
    "\n",
    "    no_fires_folders = [folder_name for folder_name in os.listdir(no_fire_original_frames_folder) if\n",
    "                        os.path.isdir(os.path.join(no_fire_original_frames_folder, folder_name))]\n",
    "    \n",
    "\n",
    "    fires_folders = [folder_name for folder_name in os.listdir(fire_original_frames_folder) if\n",
    "                        os.path.isdir(os.path.join(fire_original_frames_folder, folder_name))]\n",
    "\n",
    "    first_split_perctentage = p[0] + p[1]\n",
    "\n",
    "    random.shuffle(no_fires_folders)\n",
    "    random.shuffle(fires_folders)\n",
    "\n",
    "    total_no_fires = len(no_fires_folders)\n",
    "    total_fires = len(fires_folders)\n",
    "\n",
    "    first_split_no_fires = no_fires_folders[:int(total_no_fires * first_split_perctentage)]\n",
    "    first_split_fires = fires_folders[:int(total_fires * first_split_perctentage)]\n",
    "\n",
    "    remaining_no_fires = no_fires_folders[int(total_no_fires * first_split_perctentage):]\n",
    "    remaining_fires = fires_folders[int(total_fires * first_split_perctentage):]\n",
    "\n",
    "    os.makedirs(destination_path / \"TRAINING_SET\" / \"0\", exist_ok=True)\n",
    "    os.makedirs(destination_path / \"TRAINING_SET\" / \"1\", exist_ok=True)\n",
    "\n",
    "    os.makedirs(destination_path / \"TEST_SET\" / \"0\", exist_ok=True)\n",
    "    os.makedirs(destination_path / \"TEST_SET\" / \"1\", exist_ok=True)\n",
    "\n",
    "    os.makedirs(train_splitted_annotations_path / \"0\", exist_ok=True)\n",
    "    os.makedirs(train_splitted_annotations_path / \"1\", exist_ok=True)\n",
    "\n",
    "    os.makedirs(test_splitted_annotations_path / \"0\", exist_ok=True)\n",
    "    os.makedirs(test_splitted_annotations_path / \"1\", exist_ok=True)\n",
    "\n",
    "    for folder in first_split_no_fires:\n",
    "        shutil.copytree(no_fire_original_frames_folder / folder, destination_path / \"TRAINING_SET\" / \"0\" / folder)\n",
    "        rtf_file = folder.split(\".\")[0] + \".rtf\"\n",
    "        shutil.copyfile(train_original_annotations_path / \"0\"/ rtf_file, train_splitted_annotations_path / \"0\" / rtf_file)\n",
    "    \n",
    "    for folder in first_split_fires:\n",
    "        shutil.copytree(fire_original_frames_folder / folder, destination_path / \"TRAINING_SET\" / \"1\" / folder)\n",
    "        rtf_file = folder.split(\".\")[0] + \".rtf\"\n",
    "        shutil.copyfile(train_original_annotations_path / \"1\"/ rtf_file, train_splitted_annotations_path / \"1\" / rtf_file)\n",
    "    \n",
    "    for folder in remaining_no_fires:\n",
    "        shutil.copytree(no_fire_original_frames_folder / folder, destination_path / \"TEST_SET\" / \"0\" / folder)\n",
    "        rtf_file = folder.split(\".\")[0] + \".rtf\"\n",
    "        shutil.copyfile(train_original_annotations_path / \"0\"/ rtf_file, test_splitted_annotations_path / \"0\" / rtf_file)\n",
    "\n",
    "    for folder in remaining_fires:\n",
    "        shutil.copytree(fire_original_frames_folder / folder, destination_path / \"TEST_SET\" / \"1\" / folder)\n",
    "        rtf_file = folder.split(\".\")[0] + \".rtf\"\n",
    "        shutil.copyfile(train_original_annotations_path / \"1\"/ rtf_file, test_splitted_annotations_path / \"1\" / rtf_file)\n",
    "\n",
    "    if mode == \"classic\":\n",
    "        os.makedirs(destination_path / \"VALIDATION_SET\" / \"0\", exist_ok=True)\n",
    "        os.makedirs(destination_path / \"VALIDATION_SET\" / \"1\", exist_ok=True)\n",
    "\n",
    "        os.makedirs(val_splitted_annotations_path / \"0\", exist_ok=True)\n",
    "        os.makedirs(val_splitted_annotations_path / \"1\", exist_ok=True)\n",
    "        \n",
    "        val_num_no_fires = int(total_no_fires * p[1])\n",
    "        val_num_fires = int(total_fires * p[1])\n",
    "\n",
    "        second_split_no_fires = first_split_no_fires[:val_num_no_fires]\n",
    "        second_split_fires = first_split_fires[:val_num_fires]\n",
    "        \n",
    "        for folder in second_split_no_fires:\n",
    "            shutil.move(destination_path / \"TRAINING_SET\" / \"0\" / folder, destination_path / \"VALIDATION_SET\" / \"0\" / folder)\n",
    "            rtf_file = folder.split(\".\")[0] + \".rtf\"\n",
    "            shutil.copyfile(train_splitted_annotations_path / \"0\" / rtf_file, val_splitted_annotations_path / \"0\" / rtf_file)\n",
    "\n",
    "        for folder in second_split_fires:\n",
    "            shutil.move(destination_path / \"TRAINING_SET\" / \"1\" / folder, destination_path / \"VALIDATION_SET\" / \"1\" / folder)\n",
    "            rtf_file = folder.split(\".\")[0] + \".rtf\"\n",
    "            shutil.copyfile(train_splitted_annotations_path / \"1\" / rtf_file, val_splitted_annotations_path / \"1\" / rtf_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertiamo il numero di frame contenuto in GT: passimao da frame (1/1 con i secondi) al numero di frame veritiero che tiene conto degli fps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math\n",
    "def extract_text_from_rtf(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        rtf_content = file.read()\n",
    "\n",
    "    if rtf_content.__contains__(\"\\\\rtf1\"):\n",
    "        # Trova il testo tra '\\f0\\fs24 \\cf0 ' e '}'\n",
    "        match = re.search(r'\\\\f0\\\\fs24 \\\\cf0 (.*?)\\}', rtf_content)\n",
    "\n",
    "        if match:\n",
    "            extracted_text = match.group(1)\n",
    "            return extracted_text.strip()\n",
    "        else:\n",
    "            return None\n",
    "    else: \n",
    "        return rtf_content\n",
    "\n",
    "\n",
    "def process_videos(video_folder: Path, gt_folder: Path):\n",
    "    video_list = os.listdir(video_folder)\n",
    "    for video in video_list:\n",
    "        # Get frame rate\n",
    "        cap = cv2.VideoCapture(str(video_folder / video))\n",
    "        frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "        cap.release()\n",
    "\n",
    "        # Get video annotation\n",
    "        label = extract_text_from_rtf(os.path.join(gt_folder, video.split(\".\")[0] + \".rtf\"))\n",
    "\n",
    "        # Get frame number\n",
    "        frame_number = int(label.split(\",\")[0])\n",
    "\n",
    "        # Get other info\n",
    "        other_info = label.split(\",\")[1:] # es. ['Smoke', 'Fire']\n",
    "\n",
    "        # Replace the content of the file rtf\n",
    "        with open(os.path.join(gt_folder, video.split(\".\")[0] + \".rtf\"), 'w') as file:\n",
    "            file.write(str(math.ceil(frame_number*frame_rate)) + \",\" + \",\".join(other_info))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataset_management.adjust_frame import *\n",
    "process_videos( train_videos_path / \"1\", train_original_annotations_path / \"1\")\n",
    "split_dataset(train_original_frames_path, splitted_frames_path, mode=\"classic\", p=[0.8,0.1,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Piccolo script che copia i video di test nella cartella test_data/TEST_VIDEOS, in maniera tale da poterli utilizzare per il test finale\n",
    "\n",
    "src = test_splitted_frames_path\n",
    "dst = test_data_videos_path\n",
    "main_video_folder = videos_path / \"TRAINING_SET\"\n",
    "\n",
    "for class_folder in os.listdir(src):\n",
    "    for test_video in os.listdir(src / class_folder):\n",
    "        shutil.copy(main_video_folder / class_folder / test_video, dst / (\"{}_\".format(class_folder) + test_video ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('MachineLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a2c952ceb315243f34ba302acbe0fb5218585a422897d4fb07b81cc17398136"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
